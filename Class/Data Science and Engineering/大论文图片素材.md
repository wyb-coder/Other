# 数据科学与工程大作业——报告素材与优化指南

本文档旨在为最终的大作业报告提供素材支持，重点说明在报告的各个章节中**应插入的图表、伪代码及核心公式**，并对原有的实施方案进行**不仅“眼前一亮”且具备“真实工程感”的优化**。

---

## 第一章：基础设施环境搭建 (Infrastructure)

### 1.1 方案优化建议：资源监控与压测

**优化点**：不要仅通过 `jps` 证明“装好了”，而要证明系统是“健康”的。

- **做法**：在启动集群后，记录一下虚拟机的内存和 CPU 基线。运行测试任务时，截图资源占用峰值。
- **亮点**：这体现了“运维意识”，这是工程类课程非常看重的。相比于复杂的 Docker 编排，**对自己机器性能边界的认知**更显真实。

### 1.2 报告素材清单

#### 【图表插入点】

1.  **Hadoop 集群拓扑图 (Type: 架构图)**
    - _内容_：展示 NameNode, DataNode, ResourceManager, NodeManager 的进程分布。
    - _工具_：Visio / Draw.io
    - _图注_：图 1-1 Hadoop 伪分布式环境进程拓扑
2.  **资源监控仪表盘 (Type: 截图)**
    - _内容_：HDFS Web UI (9870 端口) 的 "Overview" 页面，展示 Live Nodes 和 DFS Used。
    - _图注_：图 1-2 HDFS 节点健康状态概览

#### 【伪代码/配置】

不要贴大段 XML。只展示核心调优参数：

```xml
<!-- 展示为了防崩溃做的内存限制关键配置 -->
<property>
    <name>yarn.nodemanager.resource.memory-mb</name>
    <value>2048</value> <!-- 明确说明根据本机 8G 内存做的适配 -->
</property>
```

---

## 第二章：数据预处理与扩增 (Preprocessing)

### 2.1 方案优化建议：统计学验证（Data Profiling）

**优化点**：不要只说“我扩增了”，要证明“扩增后的数据还是像真实数据”。

- **做法**：在报告中放一张**“直方图对比图”**。对比 Day1 (原始) 和 Day3 (生成) 的车速分布。
- **亮点**：**Data Profiling (数据画像)** 是专业数据工程师的第一步。如果两条曲线吻合度高，证明你的扩增算法（噪声+周末衰减）是科学的，而不是瞎造的。

### 2.2 报告素材清单

#### 【公式插入点】

在描述数据清洗规则时，使用集合语言描述，显得更学术：

$$
D_{clean} = \{ r \in D \mid r.speed \in [0, 150] \land r.volume \ge 0 \}
$$

在描述噪声注入（扩增）时：

$$
v_{new} = v_{old} \times (1 + \epsilon), \quad \epsilon \sim N(0, 0.05^2)
$$

_(解释：新的流量是旧流量加上一个服从正态分布的随机扰动)_

#### 【图表插入点】

1.  **数据清洗流水线 (Type: 流程图)**
    - _内容_：Load CSV -> Null Check -> Boundary Check -> Interpolation -> Output
    - _工具_：ProcessOn / Visio
    - **前后数据分布对比 (Type: 统计图)**原始数据与合成数据分布对比直方图 
    - _内容_：用 Matplotlib/Excel 画两个重叠的直方图（蓝色=原始，橙色=扩增）。
    - _图注_：图 2-2 原始数据与合成数据的速度分布一致性检验

#### 【伪代码】

描述 KNN 插值逻辑：

```text
Algorithm: Missing Value Imputation (KNN Strategy)
Input: TimeSeries T, WindowSize k
For each point p in T:
    If p.value is MISSING:
        Find k nearest valid neighbors (pre_k, post_k)
        p.value = Average(neighbors) + Random_Jitter()
    End If
End For
```

---

## 第三章：数据采集与存储 (Ingestion & Storage)

### 3.1 方案优化建议：冷热数据分层设计（Lambda-like）

**优化点**：明确区分 HDFS 和 HBase 的用途。

- **做法**：在报告中强调：HDFS 存的是 **Immutable Raw Data (不可变原始数据)**，用于全量跑批；HBase 存的是 **Indexed View (索引视图)**，用于随机查询。
- **亮点**：这展示了你懂**“Lambda 架构”**的 Batch Layer 和 Speed Layer 的区别，而不是为了存而存。

### 3.2 报告素材清单

#### 【图表插入点】

1.  **数据流向架构图 (Type: 核心架构图)**
    - _内容_：左边是 CSV 文件 -> 中间是 Flume (Agent) -> 分出两条线：一条去 HDFS，一条去 HBase。
    - _图注_：图 3-1 基于 Flume 的双路数据采集架构
2.  **HBase 数据模型图 (Type: 示意图)**
    - _内容_：画一个表格示意图，展示 RowKey 是怎么拼出来的，列族 CF1 下面有哪些列。
    - _图注_：图 3-3 宽表模型逻辑视图

#### 【公式插入点】

**RowKey 设计原理（必写！）**：

$$
RowKey = Hash(MonitorID)_{prefix} \oplus Reverse(MonitorID) \oplus (Long.MAX - Timestamp)
$$

_解释：Hash 解决热点，Reverse 增加散列度，倒序时间戳保证最新数据 `Scan` 及其最快。_

---

## 第四章：HBase 高性能查询 (Query)

### 4.1 方案优化建议：服务器端过滤（Filter Pushdown）

**优化点**：对比“客户端过滤”和“服务器端过滤”。

- **做法**：在文字描述中指出，我们不把所有数据拉到本地再过滤，而是使用 HBase 的 `FilterList` 在 RegionServer 端直接过滤。
- **亮点**：**“谓词下推” (Predicate Pushdown)** 是数据库优化的专业术语。提到这个词，老师就知道你懂底层原理。

### 4.2 报告素材清单

#### 【图表插入点】

1.  **查询扫描范围示意图 (Type: 示意图)**
    - _内容_：画一个长条代表全表。并在其中标出 StartRow 和 StopRow 截取的一小段。
    - _图注_：图 4-1 RowKey 的范围扫描(Range Scan)机制
2.  **HBase Shell 查询截图 (Type: 截图)**
    - _内容_：`scan 'traffic', {STARTROW=>'...', STOPROW=>'...'}` 的执行结果。

#### 【伪代码】

描述 SQL 到 HBase API 的翻译逻辑：

```text
Function ExecuteQuery(sensor_id, start_time, end_time):
    // 1. Construct RowKey Range
    start_key = GenerateRowKey(sensor_id, end_time)  // 注意：倒序时间存，所以 EndTime 是 StartRow
    stop_key  = GenerateRowKey(sensor_id, start_time)

    // 2. Configure Scanner
    scan = New Scan()
    scan.setStartRow(start_key)
    scan.setStopRow(stop_key)

    // 3. Server-side Execution
    result = hbase_client.getScanner(scan)
    return result
```

---

## 第五章：聚合计算 (Aggregation)

### 5.1 方案优化建议：处理数据倾斜 (Data Skew Handling)

**优化点**：假定某个监测点数据特别多（比如市中心），普通聚合会卡死。

- **做法**：在方案主要提到“虽然本数据集可能分布均匀，但为生产环境考虑，我们在 Key 中加入随机前缀进行两阶段聚合”。
- **亮点**：**数据倾斜**是面试和工程中最棘手的问题，能主动考虑到这一点（哪怕代码里只写了注释），含金量极高。

### 5.2 报告素材清单

#### 【图表插入点】

1.  **Spark/MR 执行阶段图 (Type: 流程图)**
    - _内容_：Map/Read -> Shuffle (按 ID 分组) -> Reduce/Window Aggregation -> Write
    - _工具_：Visio
2.  **作业运行 DAG 图 (Type: 截图)**
    - _内容_：Spark Web UI (4040 端口) 的 Stage 划分图。
    - _图注_：图 5-2 Spark 作业 Stage 与宽依赖划分

#### 【公式插入点】

描述 15 分钟窗口的计算：

$$
W_i = \lfloor \frac{t - t_0}{15 \times 60} \rfloor
$$

$$
Speed_{avg} = \frac{\sum_{t \in W_i} speed_t}{|W_i|}
$$

---

## 第六章：相关性分析 (Analysis)

### 6.1 方案优化建议：热力图可视化 (Heatmap)

**优化点**：直接看相关系数矩阵（一堆数字）很累，而且不直观。

- **做法**：将计算出的皮尔逊相关系数矩阵，用 Python Matplotlib/Seaborn 画成热力图（Heatmap）。颜色越深代表相关性越强。
- **亮点**：数据**可视化**能力。老师一眼就能看到“哪些路段相关性强”，这比给出一个 CSV 文件震撼得多。
- **额外亮点**：稍微分析一下结果。比如“发现 A 路段和 B 路段相关性高达 0.9，推测它们可能位于同一条主干道上下游”。**（数据洞察力）**

### 6.2 报告素材清单

#### 【公式插入点】

必须放皮尔逊系数公式（显得专业）：

$$
\rho_{X,Y} = \frac{E[(X-\mu_X)(Y-\mu_Y)]}{\sigma_X \sigma_Y}
$$

#### 【图表插入点】

1.  **相关性热力图 (Type: 结果图)**
    - _内容_：10x10 或 20x20 的红蓝方格图。
    - _图注_：图 6-1 核心路段流量相关性矩阵热力图
2.  **双重循环 vs 矩阵运算效率对比 (Type: 统计图)**
    - _内容_：画一个简单的折线图。X 轴是监测点数量，Y 轴是耗时。Line1 是 $O(N^2)$ 急速上升，Line2 是矩阵运算平缓上升。
    - _图注_：图 6-2 分布式矩阵计算与传统循环的性能复杂度对比

---

## 总结：如何体现“非完全 AI 生成”

1.  **多截图**：AI 生成不了你本地的 Task Manager、HDFS 页面、运行日志报错（把解决报错的过程写进实验心得里，非常真实）。
2.  **多分析数据**：AI 可以写代码，但很难结合“交通物理意义”去解释数据。在报告里多写一点“为什么周末早高峰消失了？”这类的话。
3.  **强调局限性**：在结论里老实承认“单机伪分布式受限于内存，导致 Spark 分区数不能设太大”。这种**诚实的工程妥协**是人类工程师的特征。

# Part 1

![image-20251222165926821](D:\Study\CS Study\Note 2024-\All Photo\image-20251222165926821.png)

![image-20251222165941746](D:\Study\CS Study\Note 2024-\All Photo\image-20251222165941746.png)

![image-20251222165955176](D:\Study\CS Study\Note 2024-\All Photo\image-20251222165955176.png)

![image-20251222170043232](D:\Study\CS Study\Note 2024-\All Photo\image-20251222170043232.png)

---

# Project 图片详细说明

以下是与 `大论文文字素材.md` 中 **【图片 X】** 标注对应的图片详细说明。

---

## 【图片 1：Docker 容器化集群架构图】

**图注**：图 1-1 Docker 容器化大数据集群架构

**内容描述**：

- 展示 11 个 Docker 容器的依赖关系和网络拓扑
- 分层展示：
  - **存储层**：NameNode, DataNode (HDFS)
  - **计算层**：ResourceManager, NodeManager (YARN), Spark Master, Spark Worker
  - **NoSQL 层**：HBase Master, HBase RegionServer
  - **协调层**：ZooKeeper
  - **采集层**：Flume Agent
- 用箭头表示依赖关系和数据流向

**建议工具**：Draw.io / Visio

**关键元素**：

```
┌─────────────────────────────────────────────────────────┐
│                    Docker Network                        │
│  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────────┐ │
│  │NameNode │←→│DataNode │  │ZooKeeper│←→│HBase Master │ │
│  └────┬────┘  └────┬────┘  └────┬────┘  └──────┬──────┘ │
│       │            │            │               │        │
│       ▼            ▼            ▼               ▼        │
│  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────────┐ │
│  │Resource │  │  Node   │  │ Spark   │  │RegionServer │ │
│  │ Manager │  │ Manager │  │ Master  │  └─────────────┘ │
│  └─────────┘  └─────────┘  └────┬────┘                  │
│                                 ▼                        │
│                           ┌──────────┐                   │
│                           │  Flume   │                   │
│                           └──────────┘                   │
└─────────────────────────────────────────────────────────┘
```

---

## 【图片 2：HDFS Web UI 健康状态截图】

**图注**：图 1-2 HDFS 集群健康状态监控界面

**内容描述**：

- 访问地址：http://localhost:50070
- 截图要点：
  1. **Overview** 标签页：显示 Live Nodes = 1, Dead Nodes = 0
  2. **DFS Used**：显示已用空间约 5.3 MB
  3. **Configured Capacity**：显示总容量
- 证明 HDFS 集群正常运行

**获取方式**：浏览器截图

---

## 【图片 3：原始数据与合成数据分布对比直方图】

**图注**：图 2-1 原始数据与合成数据的流量分布一致性验证

**内容描述**：

- **X 轴**：流量 (volume) 区间
- **Y 轴**：频率 (frequency)
- **两条曲线**：
  - 蓝色：原始数据（周五/周六）
  - 橙色：合成数据（生成的 Mon-Thu, Sun）
- **重叠区域越大**，说明分布越一致

**建议代码**：

```python
import matplotlib.pyplot as plt
plt.hist(original_data['volume'], alpha=0.5, label='Original', bins=30)
plt.hist(synthetic_data['volume'], alpha=0.5, label='Synthetic', bins=30)
plt.legend()
plt.savefig('distribution_comparison.png')
```

---

## 【图片 4：7 天流量时序曲线对比图】

**图注**：图 2-2 7 天流量时序变化曲线

**内容描述**：

- **X 轴**：时间 (03-01 ~ 03-07, 共 7 天)
- **Y 轴**：每小时总流量
- **曲线特征**：
  - 工作日（周一~周五）：明显的早高峰 (7-9 时)、午间低谷、晚高峰 (17-19 时)
  - 周末（周六日）：早高峰延迟、整体流量下降 10-15%
  - **周五晚间**：流量因放学效应比其他工作日高约 8%

**关键发现标注**：用箭头标注 "Friday Evening Effect" 和 "Weekend Pattern"

---

## 【图片 5：Lambda 架构数据流向图】

**图注**：图 3-1 基于 Lambda 架构的双路数据存储设计

**内容描述**：

- **输入**：82_processed.csv (93,234 行)
- **分流**：Flume Agent 或手动上传
- **Batch Layer**：HDFS `/traffic/82_processed.csv`
  - 用途：Spark 离线批处理
  - 特点：Immutable, Append-only
- **Speed Layer**：HBase `traffic` 表
  - 用途：毫秒级点查询
  - 特点：Indexed by RowKey

**视觉设计**：左右分支结构，左边 HDFS 图标，右边 HBase 图标

---

## 【图片 6：RowKey 结构设计示意图】

**图注**：图 4-1 HBase RowKey 复合设计结构

**内容描述**：

- 展示 RowKey 的三段式结构：
  ```
  ┌──────────────┬────────────────────────────┬───────────────┐
  │ MD5 前缀 (2) │      原始路段 ID (28)       │ 倒序时间戳 (13) │
  └──────────────┴────────────────────────────┴───────────────┘
        ↓                    ↓                       ↓
    负载均衡           支持范围查询            最新数据优先
  ```
- **示例**：
  - 输入：`road_seg_id=13G6S0C4IE...`, `time=2024-03-07 23:59`
  - 输出：`01_13G6S0C4IE..._8290172859999`

---

## 【图片 7：RowKey 范围扫描（Range Scan）示意图】

**图注**：图 5-1 基于 RowKey 的范围扫描机制

**内容描述**：

- 画一个长条代表 HBase 表的全部 RowKey 空间
- 标出 `StartRow` 和 `StopRow` 截取的一小段
- **关键强调**：
  - 因为时间戳倒序，`end_time` 对应 `StartRow`
  - `start_time` 对应 `StopRow`（与直觉相反）

**视觉设计**：

```
|←────────────────── 全表空间 ──────────────────→|
        ┌──────────────────┐
        │  StartRow        │  ← end_time
        │       ↓          │
        │   扫描范围 (k行)  │
        │       ↓          │
        │  StopRow         │  ← start_time
        └──────────────────┘
```

---

## 【图片 8：7 天流量聚合结果柱状图】

**图注**：图 6-1 7 天日总流量柱状对比

**内容描述**：

- **X 轴**：日期 (03-01 周五 ~ 03-07 周四)
- **Y 轴**：日总流量
- **柱状高度**：
  - 周五 (03-01)：438,563 ← 最高
  - 周日 (03-03)：377,350 ← 最低
- **颜色区分**：工作日用蓝色，周末用橙色

**关键发现标注**：用箭头标注 "周五最高"、"周日最低"

---

## 【图片 9：皮尔逊相关性热力图（10×10）】

**图注**：图 7-1 10 个监测点流量相关性矩阵热力图

**内容描述**：

- **矩阵大小**：10×10
- **颜色编码**：
  - 红色：高相关 (r > 0.8)
  - 橙色：中等相关 (0.6 < r < 0.8)
  - 黄色：低相关 (r < 0.6)
- **对角线**：全为 1.00（自相关）
- **高亮区域**：S2-S7 (0.93), S2-S9 (0.90) 等高相关对

**已生成文件**：`Code/Part6-Analysis/correlation_heatmap.png`

**关键发现标注**：

- 圈出 S2, S5, S7, S9 的高相关集群
- 标注 S1, S8 为"相对独立路段"

---
