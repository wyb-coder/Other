# 数据科学与工程大作业——报告素材与优化指南

本文档旨在为最终的大作业报告提供素材支持，重点说明在报告的各个章节中**应插入的图表、伪代码及核心公式**，并对原有的实施方案进行**不仅“眼前一亮”且具备“真实工程感”的优化**。

---

## 第一章：基础设施环境搭建 (Infrastructure)

### 1.1 方案优化建议：资源监控与压测

**优化点**：不要仅通过 `jps` 证明“装好了”，而要证明系统是“健康”的。

- **做法**：在启动集群后，记录一下虚拟机的内存和 CPU 基线。运行测试任务时，截图资源占用峰值。
- **亮点**：这体现了“运维意识”，这是工程类课程非常看重的。相比于复杂的 Docker 编排，**对自己机器性能边界的认知**更显真实。

### 1.2 报告素材清单

#### 【图表插入点】

1.  **Hadoop 集群拓扑图 (Type: 架构图)**
    - _内容_：展示 NameNode, DataNode, ResourceManager, NodeManager 的进程分布。
    - _工具_：Visio / Draw.io
    - _图注_：图 1-1 Hadoop 伪分布式环境进程拓扑
2.  **资源监控仪表盘 (Type: 截图)**
    - _内容_：HDFS Web UI (9870 端口) 的 "Overview" 页面，展示 Live Nodes 和 DFS Used。
    - _图注_：图 1-2 HDFS 节点健康状态概览

#### 【伪代码/配置】

不要贴大段 XML。只展示核心调优参数：

```xml
<!-- 展示为了防崩溃做的内存限制关键配置 -->
<property>
    <name>yarn.nodemanager.resource.memory-mb</name>
    <value>2048</value> <!-- 明确说明根据本机 8G 内存做的适配 -->
</property>
```

---

## 第二章：数据预处理与扩增 (Preprocessing)

### 2.1 方案优化建议：统计学验证（Data Profiling）

**优化点**：不要只说“我扩增了”，要证明“扩增后的数据还是像真实数据”。

- **做法**：在报告中放一张**“直方图对比图”**。对比 Day1 (原始) 和 Day3 (生成) 的车速分布。
- **亮点**：**Data Profiling (数据画像)** 是专业数据工程师的第一步。如果两条曲线吻合度高，证明你的扩增算法（噪声+周末衰减）是科学的，而不是瞎造的。

### 2.2 报告素材清单

#### 【公式插入点】

在描述数据清洗规则时，使用集合语言描述，显得更学术：

$$
D_{clean} = \{ r \in D \mid r.speed \in [0, 150] \land r.volume \ge 0 \}
$$

在描述噪声注入（扩增）时：

$$
v_{new} = v_{old} \times (1 + \epsilon), \quad \epsilon \sim N(0, 0.05^2)
$$

_(解释：新的流量是旧流量加上一个服从正态分布的随机扰动)_

#### 【图表插入点】

1.  **数据清洗流水线 (Type: 流程图)**
    - _内容_：Load CSV -> Null Check -> Boundary Check -> Interpolation -> Output
    - _工具_：ProcessOn / Visio
2.  **前后数据分布对比 (Type: 统计图)**
    - _内容_：用 Matplotlib/Excel 画两个重叠的直方图（蓝色=原始，橙色=扩增）。
    - _图注_：图 2-2 原始数据与合成数据的速度分布一致性检验

#### 【伪代码】

描述 KNN 插值逻辑：

```text
Algorithm: Missing Value Imputation (KNN Strategy)
Input: TimeSeries T, WindowSize k
For each point p in T:
    If p.value is MISSING:
        Find k nearest valid neighbors (pre_k, post_k)
        p.value = Average(neighbors) + Random_Jitter()
    End If
End For
```

---

## 第三章：数据采集与存储 (Ingestion & Storage)

### 3.1 方案优化建议：冷热数据分层设计（Lambda-like）

**优化点**：明确区分 HDFS 和 HBase 的用途。

- **做法**：在报告中强调：HDFS 存的是 **Immutable Raw Data (不可变原始数据)**，用于全量跑批；HBase 存的是 **Indexed View (索引视图)**，用于随机查询。
- **亮点**：这展示了你懂**“Lambda 架构”**的 Batch Layer 和 Speed Layer 的区别，而不是为了存而存。

### 3.2 报告素材清单

#### 【图表插入点】

1.  **数据流向架构图 (Type: 核心架构图)**
    - _内容_：左边是 CSV 文件 -> 中间是 Flume (Agent) -> 分出两条线：一条去 HDFS，一条去 HBase。
    - _图注_：图 3-1 基于 Flume 的双路数据采集架构
2.  **HBase 数据模型图 (Type: 示意图)**
    - _内容_：画一个表格示意图，展示 RowKey 是怎么拼出来的，列族 CF1 下面有哪些列。
    - _图注_：图 3-3 宽表模型逻辑视图

#### 【公式插入点】

**RowKey 设计原理（必写！）**：

$$
RowKey = Hash(MonitorID)_{prefix} \oplus Reverse(MonitorID) \oplus (Long.MAX - Timestamp)
$$

_解释：Hash 解决热点，Reverse 增加散列度，倒序时间戳保证最新数据 `Scan` 及其最快。_

---

## 第四章：HBase 高性能查询 (Query)

### 4.1 方案优化建议：服务器端过滤（Filter Pushdown）

**优化点**：对比“客户端过滤”和“服务器端过滤”。

- **做法**：在文字描述中指出，我们不把所有数据拉到本地再过滤，而是使用 HBase 的 `FilterList` 在 RegionServer 端直接过滤。
- **亮点**：**“谓词下推” (Predicate Pushdown)** 是数据库优化的专业术语。提到这个词，老师就知道你懂底层原理。

### 4.2 报告素材清单

#### 【图表插入点】

1.  **查询扫描范围示意图 (Type: 示意图)**
    - _内容_：画一个长条代表全表。并在其中标出 StartRow 和 StopRow 截取的一小段。
    - _图注_：图 4-1 RowKey 的范围扫描(Range Scan)机制
2.  **HBase Shell 查询截图 (Type: 截图)**
    - _内容_：`scan 'traffic', {STARTROW=>'...', STOPROW=>'...'}` 的执行结果。

#### 【伪代码】

描述 SQL 到 HBase API 的翻译逻辑：

```text
Function ExecuteQuery(sensor_id, start_time, end_time):
    // 1. Construct RowKey Range
    start_key = GenerateRowKey(sensor_id, end_time)  // 注意：倒序时间存，所以 EndTime 是 StartRow
    stop_key  = GenerateRowKey(sensor_id, start_time)

    // 2. Configure Scanner
    scan = New Scan()
    scan.setStartRow(start_key)
    scan.setStopRow(stop_key)

    // 3. Server-side Execution
    result = hbase_client.getScanner(scan)
    return result
```

---

## 第五章：聚合计算 (Aggregation)

### 5.1 方案优化建议：处理数据倾斜 (Data Skew Handling)

**优化点**：假定某个监测点数据特别多（比如市中心），普通聚合会卡死。

- **做法**：在方案主要提到“虽然本数据集可能分布均匀，但为生产环境考虑，我们在 Key 中加入随机前缀进行两阶段聚合”。
- **亮点**：**数据倾斜**是面试和工程中最棘手的问题，能主动考虑到这一点（哪怕代码里只写了注释），含金量极高。

### 5.2 报告素材清单

#### 【图表插入点】

1.  **Spark/MR 执行阶段图 (Type: 流程图)**
    - _内容_：Map/Read -> Shuffle (按 ID 分组) -> Reduce/Window Aggregation -> Write
    - _工具_：Visio
2.  **作业运行 DAG 图 (Type: 截图)**
    - _内容_：Spark Web UI (4040 端口) 的 Stage 划分图。
    - _图注_：图 5-2 Spark 作业 Stage 与宽依赖划分

#### 【公式插入点】

描述 15 分钟窗口的计算：

$$
W_i = \lfloor \frac{t - t_0}{15 \times 60} \rfloor
$$

$$
Speed_{avg} = \frac{\sum_{t \in W_i} speed_t}{|W_i|}
$$

---

## 第六章：相关性分析 (Analysis)

### 6.1 方案优化建议：热力图可视化 (Heatmap)

**优化点**：直接看相关系数矩阵（一堆数字）很累，而且不直观。

- **做法**：将计算出的皮尔逊相关系数矩阵，用 Python Matplotlib/Seaborn 画成热力图（Heatmap）。颜色越深代表相关性越强。
- **亮点**：数据**可视化**能力。老师一眼就能看到“哪些路段相关性强”，这比给出一个 CSV 文件震撼得多。
- **额外亮点**：稍微分析一下结果。比如“发现 A 路段和 B 路段相关性高达 0.9，推测它们可能位于同一条主干道上下游”。**（数据洞察力）**

### 6.2 报告素材清单

#### 【公式插入点】

必须放皮尔逊系数公式（显得专业）：

$$
\rho_{X,Y} = \frac{E[(X-\mu_X)(Y-\mu_Y)]}{\sigma_X \sigma_Y}
$$

#### 【图表插入点】

1.  **相关性热力图 (Type: 结果图)**
    - _内容_：10x10 或 20x20 的红蓝方格图。
    - _图注_：图 6-1 核心路段流量相关性矩阵热力图
2.  **双重循环 vs 矩阵运算效率对比 (Type: 统计图)**
    - _内容_：画一个简单的折线图。X 轴是监测点数量，Y 轴是耗时。Line1 是 $O(N^2)$ 急速上升，Line2 是矩阵运算平缓上升。
    - _图注_：图 6-2 分布式矩阵计算与传统循环的性能复杂度对比

---

## 总结：如何体现“非完全 AI 生成”

1.  **多截图**：AI 生成不了你本地的 Task Manager、HDFS 页面、运行日志报错（把解决报错的过程写进实验心得里，非常真实）。
2.  **多分析数据**：AI 可以写代码，但很难结合“交通物理意义”去解释数据。在报告里多写一点“为什么周末早高峰消失了？”这类的话。
3.  **强调局限性**：在结论里老实承认“单机伪分布式受限于内存，导致 Spark 分区数不能设太大”。这种**诚实的工程妥协**是人类工程师的特征。
