# 《数字图像处理》第二次作业报告：人体部件检测系统

> **学号**：2025354100103  
> **姓名**：王耀彬  
> **日期**：2025 年 12 月 26 日

---

## 一、实验概述

### 1.1 实验目标

本次实验旨在构建一个**实时人体部件检测系统**，能够从摄像头视频流中检测人脸及其面部器官（眼睛、鼻子、嘴巴、耳朵、瞳孔），并在画面中进行可视化标注。

### 1.2 技术路线

系统采用两种核心技术：

| 检测目标                     | 技术方案                                |
| ---------------------------- | --------------------------------------- |
| 人脸、眼睛、鼻子、嘴巴、耳朵 | **Haar 级联分类器** (OpenCV 内置)       |
| 瞳孔                         | **基于形状分析的轮廓检测** (自实现算法) |

---

### 1.3 实验原理

#### 1.3.1 Haar 特征与级联分类器

**Haar 特征**是 Viola-Jones 人脸检测算法的基础，使用简单的矩形特征描述图像局部区域：

$$f_{Haar} = \sum_{i \in white} I(i) - \sum_{j \in black} I(j)$$

其中 $I(i)$ 表示像素 $i$ 的灰度值。

**积分图（Integral Image）**实现 $O(1)$ 时间复杂度的特征计算：

$$II(x,y) = \sum_{x' \leq x, y' \leq y} I(x',y')$$

任意矩形区域的像素和可通过 4 次查表计算：

$$\sum_{(x,y) \in R} I(x,y) = II(D) - II(B) - II(C) + II(A)$$

**AdaBoost 级联分类器**：多个弱分类器按层级组织，每层快速拒绝非目标区域。

#### 1.3.2 图像卷积与滤波

高斯模糊用于预处理去噪：

$$G(x,y) = \frac{1}{2\pi\sigma^2} e^{-\frac{x^2+y^2}{2\sigma^2}}$$

卷积操作：

$$I'(x,y) = I(x,y) * G(x,y) = \sum_{i,j} I(x-i, y-j) \cdot G(i,j)$$

#### 1.3.3 二值化与形态学操作

**阈值分割**：

$$I_{bin}(x,y) = \begin{cases} 255 & \text{if } I(x,y) > T \\ 0 & \text{otherwise} \end{cases}$$

**形态学操作**：

- 腐蚀(Erosion)：$A \ominus B$
- 膨胀(Dilation)：$A \oplus B$
- 开运算(Opening)：$(A \ominus B) \oplus B$
- 闭运算(Closing)：$(A \oplus B) \ominus B$

#### 1.3.4 轮廓分析与几何特征

**轮廓面积**：

$$Area = \frac{1}{2} \left| \sum_{i=0}^{n-1} (x_i y_{i+1} - x_{i+1} y_i) \right|$$

**轮廓周长**：

$$Perimeter = \sum_{i=0}^{n-1} \sqrt{(x_{i+1}-x_i)^2 + (y_{i+1}-y_i)^2}$$

**圆形度**：

$$Circularity = \frac{4\pi \cdot Area}{Perimeter^2}$$

完美圆形的圆形度 $= 1$。

#### 1.3.5 图像插值

**最近邻插值（INTER_NEAREST）**：

$$I'(x,y) = I(round(x), round(y))$$

产生方块效果，用于马赛克生成。

**双线性插值（INTER_LINEAR）**：

$$I'(x,y) = (1-a)(1-b)I_{00} + a(1-b)I_{10} + (1-a)bI_{01} + abI_{11}$$

产生平滑效果，用于降采样。

---

## 二、基线系统实现

### 2.1 系统架构设计

整个检测系统封装在 `FaceDetector` 类中，采用模块化设计：

```python
class FaceDetector:
    def __init__(self):
        # 加载所有级联分类器
        self.cascades = {}
        for name, path in CASCADE_PATHS.items():
            self.cascades[name] = cv2.CascadeClassifier(path)
```

系统共加载 **6 个** Haar 级联分类器文件：

| 分类器文件                        | 用途     |
| --------------------------------- | -------- |
| `haarcascade_frontalface_alt.xml` | 正脸检测 |
| `haarcascade_eye.xml`             | 眼睛检测 |
| `haarcascade_mcs_nose.xml`        | 鼻子检测 |
| `haarcascade_mcs_mouth.xml`       | 嘴巴检测 |
| `haarcascade_mcs_leftear.xml`     | 左耳检测 |
| `haarcascade_mcs_rightear.xml`    | 右耳检测 |

---

### 2.2 全局面部检测

#### 2.2.1 算法原理

Haar 级联分类器是 Viola-Jones 人脸检测算法的实现，其核心思想是：

1. **Haar 特征**：使用简单的矩形特征（边缘特征、线特征、中心环绕特征）描述图像局部区域
2. **积分图加速**：通过积分图实现 $O(1)$ 时间复杂度的特征计算
3. **AdaBoost 级联**：多个弱分类器级联形成强分类器，逐层过滤非人脸区域

#### 2.2.2 技术实现

```python
def detect_face(self, frame, gray=None):
    if gray is None:
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    faces = self.cascades["face"].detectMultiScale(
        gray,
        scaleFactor=1.1,      # 图像金字塔缩放比例
        minNeighbors=5,       # 候选框合并阈值
        minSize=(30, 30),     # 最小检测尺寸
        flags=cv2.CASCADE_SCALE_IMAGE
    )
    return faces
```

**关键参数解析**：

- `scaleFactor=1.1`：每次图像缩小为原来的 $\frac{1}{1.1} \approx 90.9\%$，用于多尺度检测
- `minNeighbors=5`：只有当某区域被检测到 ≥5 次时才认定为人脸，有效减少误检
- `minSize=(30,30)`：过滤小于 30×30 像素的候选区域

---

### 2.3 局部器官检测（ROI 优化策略）

#### 2.3.1 设计思想

直接在全图搜索器官会导致：

- **计算开销大**：搜索范围过大
- **误检率高**：背景纹理可能被误检为器官

**解决方案**：采用 **ROI（Region of Interest）约束**，仅在人脸区域内搜索器官。

#### 2.3.2 眼睛检测

眼睛通常位于人脸的**上半部分**，因此进一步缩小搜索范围：

```python
def detect_eyes(self, frame, face_roi, gray_roi=None):
    x, y, w, h = face_roi

    # 仅在人脸上半部分(60%)搜索眼睛
    upper_half_h = int(h * 0.6)
    gray_roi = gray_roi[:upper_half_h, :]

    eyes_local = self.cascades["eye"].detectMultiScale(
        gray_roi,
        scaleFactor=1.1,
        minNeighbors=5,
        minSize=(20, 20)
    )

    # 坐标转换：局部坐标 → 全局坐标
    eyes = [(x + ex, y + ey, ew, eh) for (ex, ey, ew, eh) in eyes_local]
    return eyes
```

#### 2.3.3 嘴巴检测

嘴巴位于人脸的**下半部分**：

```python
def detect_mouth(self, frame, face_roi, gray_roi=None):
    x, y, w, h = face_roi
    lower_start = int(h * 0.5)  # 从50%位置开始搜索
    gray_roi = gray_roi[lower_start:, :]

    mouths_local = self.cascades["mouth"].detectMultiScale(
        gray_roi,
        minNeighbors=10,  # 提高阈值减少误检
        minSize=(25, 15)
    )
    # 注意：y坐标需要加上偏移量 lower_start
    mouths = [(x + mx, y + lower_start + my, mw, mh) for ...]
```

**关键设计**：嘴巴检测将 `minNeighbors` 提高到 **10**，因为嘴巴区域容易产生误检。

#### 2.3.4 耳朵检测

左右耳需要使用不同的分类器分别检测：

```python
def detect_ears(self, frame, face_roi, gray_roi=None):
    ears = {"left": [], "right": []}

    # 左耳检测
    left_ears = self.cascades["left_ear"].detectMultiScale(...)
    # 右耳检测
    right_ears = self.cascades["right_ear"].detectMultiScale(...)

    return ears
```

#### 2.3.5 耳朵检测的问题与优化

**问题发现**：在实际测试中发现，当用户呈现**侧脸**时：

1. 正脸分类器无法检测到人脸（Face: 0）
2. 耳朵检测依赖于人脸 ROI，导致耳朵也无法检测

**解决方案**：实现**全局耳朵检测**作为备选方案

```python
def detect_ears_global(self, frame, gray=None):
    """当没有检测到人脸时，在全图搜索耳朵"""
    # 直方图均衡化增强对比度
    gray = cv2.equalizeHist(gray)

    left_ears = self.cascades["left_ear"].detectMultiScale(
        gray,
        scaleFactor=1.05,    # 更精细的多尺度搜索
        minNeighbors=1,      # 降低确认阈值
        minSize=(15, 20)     # 允许更小的检测尺寸
    )
```

**参数调优对比**：

| 参数           | 原始值  | 优化后      | 说明                     |
| -------------- | ------- | ----------- | ------------------------ |
| `scaleFactor`  | 1.1     | **1.05**    | 更精细的图像金字塔       |
| `minNeighbors` | 4       | **1**       | 降低合并阈值，提高召回率 |
| `minSize`      | (25,40) | **(15,20)** | 检测更小尺寸的耳朵       |

**预处理增强**：添加 `cv2.equalizeHist()` 直方图均衡化，改善低光照条件下的对比度。

**触发逻辑**：

```python
# 当没有检测到人脸时，进行全局耳朵检测
if len(faces) == 0:
    ears = detector.detect_ears_global(frame, gray)
```

---

### 2.4 瞳孔检测（基于形状分析）

#### 2.4.1 算法概述

与其他器官不同，**瞳孔检测不使用级联分类器**，而是采用基于形状分析的自定义算法：

```
输入眼睛ROI → 灰度化 → 高斯模糊 → 图像反相 → 二值化 → 轮廓查找 → 几何筛选 → 输出瞳孔位置
```

#### 2.4.2 图像反相原理

瞳孔是眼睛中最暗的区域，直接检测黑色区域较困难。通过**图像反相**操作：

Iinv(x,y)=255−I(x,y)

使得瞳孔从暗区变为高亮区域，便于后续阈值分割。

```python
blurred = cv2.GaussianBlur(gray, (7, 7), 0)
inverted = cv2.bitwise_not(blurred)  # 图像反相
_, thresh = cv2.threshold(inverted, 200, 255, cv2.THRESH_BINARY)
```

#### 2.4.3 几何筛选

轮廓查找后可能得到多个候选区域，需要通过**几何特征**筛选出瞳孔：

1. **面积约束**：瞳孔面积应占眼睛区域的 1%~50%
2. **圆形度约束**：瞳孔接近圆形

**圆形度计算公式**：

$$Circularity = \frac{4\pi \cdot Area}{Perimeter^2}$$

其中，完美圆形的圆形度 $= 1$。

```python
for contour in contours:
    area = cv2.contourArea(contour)

    # 面积过滤
    if area < roi_area * 0.01 or area > roi_area * 0.5:
        continue

    perimeter = cv2.arcLength(contour, True)
    circularity = 4 * np.pi * area / (perimeter ** 2)

    # 圆形度阈值：>0.3
    if circularity > 0.3 and circularity > best_circularity:
        best_circularity = circularity
        (cx, cy), radius = cv2.minEnclosingCircle(contour)
        best_pupil = (int(cx), int(cy), int(radius))
```

---

### 2.5 检测状态可视化

系统在画面右上角显示**实时检测状态面板**，包含所有部位的检测计数：

```python
def draw_status_panel(frame, stats):
    status_items = [
        ("Face", stats["face"], (255, 0, 0)),      # 蓝色
        ("Eyes", stats["eyes"], (0, 255, 0)),      # 绿色
        ("Nose", stats["nose"], (0, 255, 255)),    # 黄色
        ("Mouth", stats["mouth"], (0, 0, 255)),    # 红色
        ("L-Ear", stats["left_ear"], (255, 128, 0)),   # 橙色
        ("R-Ear", stats["right_ear"], (0, 128, 255)),  # 青色
        ("Pupil", stats["pupil"], (255, 0, 255)),  # 紫色
    ]

    for name, count, color in status_items:
        indicator_color = (0, 255, 0) if count > 0 else (0, 0, 150)
        cv2.circle(frame, (...), 5, indicator_color, -1)  # 状态指示灯
```

**状态指示灯**：

- 🟢 绿色 = 检测到该部位
- 🔴 红色 = 未检测到

---

## 三、创新模块实现

### 3.1 创新模块一：AR 面具系统（真我假面）

#### 3.1.1 功能概述

实现**增强现实（AR）面具佩戴效果**，将虚拟面具图像无缝融合到检测到的人脸区域。

**核心技术**：掩膜（Mask）生成与位运算（Bitwise Operations）

#### 3.1.2 实现原理

面具融合采用经典的**位运算方法**，流程如下：

```
1. 缩放面具 → 2. 生成二值掩膜 → 3. 逆掩膜抠背景 → 4. 提取面具前景 → 5. 融合
```

**关键代码实现**：

```python
# 1. 生成二值掩膜（面具非白色区域）
mask_gray = cv2.cvtColor(mask_bgr, cv2.COLOR_BGR2GRAY)
_, mask_binary = cv2.threshold(mask_gray, 240, 255, cv2.THRESH_BINARY_INV)

# 2. 生成逆掩膜
mask_inv = cv2.bitwise_not(mask_binary)

# 3. 在人脸ROI中抠出面具形状的空洞
roi_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)

# 4. 提取面具的前景部分
mask_fg = cv2.bitwise_and(mask_bgr, mask_bgr, mask=mask_binary)

# 5. 融合背景与前景
result = cv2.add(roi_bg, mask_fg)
```

#### 3.1.3 位运算原理图解

| 步骤                     | 操作     | 说明                     |
| ------------------------ | -------- | ------------------------ |
| `bitwise_not`            | 逆掩膜   | 将面具区域变黑，背景变白 |
| `bitwise_and` + mask_inv | 背景保留 | 原图中面具位置被"抠空"   |
| `bitwise_and` + mask     | 前景提取 | 只保留面具的有效像素     |
| `add`                    | 融合     | 背景 + 前景 = 最终效果   |

#### 3.1.4 位置与尺寸调整

实际测试中发现两个问题：

1. **面具太靠下**：Haar 检测框偏下
2. **覆盖不完整**：人脸较大时面具无法覆盖整个脸部

**解决方案**：添加缩放和偏移参数

```python
def apply_mask_bitwise(self, frame, face_roi, scale=1.15, y_offset_ratio=-0.1):
    # 计算放大后的尺寸
    new_w = int(w * scale)
    new_h = int(h * scale)

    # 计算位置（居中 + 向上偏移）
    new_x = x - (new_w - w) // 2
    new_y = y - (new_h - h) // 2 + int(h * y_offset_ratio)
```

| 参数             | 值   | 作用                   |
| ---------------- | ---- | ---------------------- |
| `scale`          | 1.15 | 面具放大 15%以完整覆盖 |
| `y_offset_ratio` | -0.1 | 向上偏移 10%修正位置   |

#### 3.1.5 交互控制

| 按键 | 功能           |
| ---- | -------------- |
| `m`  | 开关面具模式   |
| `n`  | 切换下一个面具 |
| `s`  | 保存截图       |
| `q`  | 退出程序       |

---

### 3.2 创新模块二：几何约束过滤器

#### 3.2.1 设计思想

Haar 级联分类器存在**误检问题**（False Positive），例如将背景纹理误识别为嘴巴。通过引入**解剖学常识**，对检测结果进行逻辑校验，可有效降低误检率。

**核心思想**：器官位置应符合人脸解剖学规律

#### 3.2.2 约束规则

| 器官 | 约束条件   | 范围（相对人脸高度） |
| ---- | ---------- | -------------------- |
| 眼睛 | 在人脸上部 | 10% ~ 55%            |
| 鼻子 | 在人脸中部 | 25% ~ 75%            |
| 嘴巴 | 在人脸下部 | 50% ~ 95%            |

**规则配置**：

```python
CONSTRAINTS = {
    "eye_max_y": 0.55,   # 眼睛不超过人脸55%
    "nose_min_y": 0.25,  # 鼻子至少在25%以下
    "mouth_min_y": 0.50, # 嘴巴至少在50%以下
}
```

#### 3.2.3 级联约束

除了绝对位置约束，还实现了**相对位置约束**：

```python
# 鼻子必须在眼睛下方
if nose_y < eye_bottom:
    return False  # 丢弃

# 嘴巴必须在鼻子下方
if mouth_y < nose_bottom:
    return False  # 丢弃
```

#### 3.2.4 过滤流程

```
眼睛检测 → 位置过滤 → 有效眼睛
                ↓
鼻子检测 → 位置过滤 + 必须在眼睛下方 → 有效鼻子
                                    ↓
嘴巴检测 → 位置过滤 + 必须在鼻子下方 → 有效嘴巴
```

#### 3.2.5 效果对比

| 状态     | 误检情况                     |
| -------- | ---------------------------- |
| 约束关闭 | 背景可能被误检为器官         |
| 约束开启 | 不符合解剖学规律的检测被过滤 |

#### 3.2.6 交互控制

| 按键 | 功能         |
| ---- | ------------ |
| `g`  | 开关几何约束 |
| `s`  | 保存截图     |
| `q`  | 退出程序     |

---

### 3.3 创新模块三：隐私马赛克盾

#### 3.3.1 设计理念

体现对**AI 伦理**的思考。在新闻报道、监控回放等场景中，常需要保护个人隐私。本模块实现实时人脸马赛克效果。

#### 3.3.2 算法原理

马赛克效果通过**降采样+升采样**实现：

```
原图ROI → 降采样(1/15) → 最近邻插值升采样 → 方块效果
```

**核心代码**：

```python
def apply_mosaic(self, frame, roi_rect):
    # 1. 降采样（信息丢失）
    small = cv2.resize(roi, (w//level, h//level),
                       interpolation=cv2.INTER_LINEAR)

    # 2. 升采样（产生方块效果）
    mosaic = cv2.resize(small, (w, h),
                        interpolation=cv2.INTER_NEAREST)
```

#### 3.3.3 插值算法对比

| 插值方法        | 效果       | 适用场景           |
| --------------- | ---------- | ------------------ |
| `INTER_LINEAR`  | 平滑过渡   | 降采样时保留信息   |
| `INTER_NEAREST` | 锯齿方块   | 升采样时产生马赛克 |
| `INTER_CUBIC`   | 高质量平滑 | 图像放大           |

**关键**：升采样必须使用 `INTER_NEAREST` 才能产生标准马赛克效果。

#### 3.3.4 三种马赛克模式

| 模式   | 效果         | 应用场景  |
| ------ | ------------ | --------- |
| 关闭   | 正常检测     | 调试/对比 |
| 整脸   | 完全隐匿人脸 | 新闻报道  |
| 仅眼睛 | 保留部分特征 | 采访节目  |

#### 3.3.5 马赛克强度

通过 `level` 参数控制马赛克粒度：

| Level | 效果               |
| ----- | ------------------ |
| 5     | 轻微模糊           |
| 15    | 标准马赛克（默认） |
| 30    | 强烈马赛克         |

#### 3.3.6 交互控制

| 按键 | 功能           |
| ---- | -------------- |
| `p`  | 切换马赛克模式 |
| `+`  | 增加马赛克强度 |
| `-`  | 降低马赛克强度 |
| `s`  | 保存截图       |
| `q`  | 退出程序       |

---

## 四、实验结果

### 4.1 运行效果

系统能够实时检测并标注人脸及各器官：

| 检测部位 | 框线颜色 | 标签         |
| -------- | -------- | ------------ |
| 人脸     | 蓝色     | Face         |
| 眼睛     | 绿色     | Eye          |
| 鼻子     | 黄色     | Nose         |
| 嘴巴     | 红色     | Mouth        |
| 左耳     | 橙色     | L-Ear        |
| 右耳     | 青色     | R-Ear        |
| 瞳孔     | 紫色圆圈 | (中心点标记) |

### 4.2 交互功能

| 按键 | 功能           |
| ---- | -------------- |
| `q`  | 退出程序       |
| `s`  | 保存当前帧截图 |

---

## 五、技术总结

### 5.1 关键技术点

1. **Haar 级联分类器**：利用积分图和 AdaBoost 实现高效人脸检测
2. **ROI 优化策略**：通过约束搜索范围提高检测效率和准确率
3. **形状分析算法**：基于图像反相、轮廓检测和几何筛选的瞳孔定位
4. **坐标变换**：局部 ROI 坐标与全局图像坐标的正确转换

### 5.2 算法局限性

| 问题           | 原因                         |
| -------------- | ---------------------------- |
| 侧脸检测失败   | 使用的是正脸分类器           |
| 遮挡情况下误检 | Haar 特征对遮挡敏感          |
| 光照变化影响大 | 需要预处理（直方图均衡化等） |

---

## 附录

（完整源代码见附件 `baseline.py`、`ar_mask.py`、`geometry_filter.py`、`privacy_mosaic.py`）
