# 《数字图像处理》作业规划报告：人体部件检测与增强现实系统（完整版）

## 1. 作业目标深度分析

本次作业旨在构建一个实时的人体特征视觉理解系统。我们将分两个阶段实施：

- **阶段一（基线/守）：** 严格复现教材第三章的核心内容，完成从面部到瞳孔的全方位检测。
- **阶段二（创新/破与离）：** 在感知的基础上，通过 **增强现实（面具）** 、**算法优化（几何约束）**和**伦理应用（隐私保护）**三个独立维度进行深度拓展。

---

## 2. 第一阶段：基线系统实现 (Baseline Implementation)

**目标** ：构建稳健的检测底座，确保所有器官能被正确识别。

### 2.1 基础架构：级联分类器流水线

我们需要建立一个基于 `Haar Cascades` 的标准检测流。

- **全局面部检测** ：
- 使用 `haarcascade_frontalface_alt.xml`。
- **技术要点：将视频帧转为灰度图（**`<span class="citation-280">cv2.COLOR_BGR2GRAY</span>`），并使用 `<span class="citation-280">detectMultiScale</span>` 进行多尺度检测 ^1^。
- **局部器官检测（ROI 优化）** ：
- **策略** **：为了提高效率并减少误检，不在全图中搜索器官，而是在检测到的“面部区域（ROI）”内进行二次搜索 **^2^。
- **眼睛** ：加载 `haarcascade_eye.xml`，仅在面部 ROI 的上半部分搜索。
- **鼻子** ：加载 `haarcascade_mcs_nose.xml`。
- **嘴巴** ：加载 `haarcascade_mcs_mouth.xml`。
- **耳朵** **：分别加载左耳和右耳分类器 **^3^。

### 2.2 特殊算法：基于形状分析的瞳孔检测

**注意** ：瞳孔检测不使用 XML 分类器，这是基线部分的 **技术难点** 。

- **算法逻辑** ：

1. **反相与阈值** **：对图像取反（**`<span class="citation-277">~img</span>`），使黑色的瞳孔变为高亮区域，再进行二值化阈值处理 ^4^。
2. **轮廓查找** ：使用 `cv2.findContours` 提取所有形状边界。
3. **几何筛选** **：通过计算轮廓的** **面积** **（**`<span class="citation-276">contourArea</span>`）、**矩形度**和**圆形度**来过滤出瞳孔，排除干扰 ^5^。

---

## 3. 第二阶段：三大独立创新模块 (Three Innovation Modules)

这一阶段将在基线代码之上，增加三个独立的“功能开关”，分别展示图像处理在不同领域的应用潜力。

### 3.1 创新模块一：娱乐增强——“真我假面” (AR Masquerade)

**核心技术** ：掩膜（Mask）生成与位运算（Bitwise Operations）。

- **功能描述** ：实现“佩戴独特面具”的增强现实体验。不同于简单的矩形框覆盖，该模块将实现面具纹理与人脸背景的像素级融合。
- **技术实现路径** ：

1. **ROI 提取** **：锁定人脸区域 **^6^。
2. **掩膜生成** **：加载一张独特的面具图（如京剧脸谱），利用 **`<span class="citation-274">cv2.threshold</span>` 生成二值掩膜，区分前景（面具）与背景 ^7^。
3. **逆运算抠图** **：使用 **`<span class="citation-273">cv2.bitwise_not</span>` 生成逆掩膜，在原图人脸 ROI 中“抠”出黑色区域 ^8^。
4. **无缝融合** **：使用 **`<span class="citation-272">cv2.bitwise_and</span>` 和 `<span class="citation-272">cv2.add</span>` 将纯净的面具纹理填入抠出的区域，实现无缝佩戴 ^9^。

### 3.2 创新模块二：算法优化——几何约束过滤器 (Geometric Constraints)

**核心技术** ：逻辑校验与坐标变换。

- **功能描述** ：解决 Haar 分类器“瞎猜”的问题（例如把背景纹理误检为嘴巴）。通过解剖学常识，给检测器加上“逻辑锁”。
- **技术实现路径** ：

1. **建立坐标系** ：所有器官坐标 `(x, y)` 均基于面部 ROI 的相对坐标系。
2. **规则过滤器** ：在绘制矩形框之前，先进行逻辑判断：
   - `if eye_y > face_h * 0.5`: 丢弃（眼睛不可能长在下半脸）。
   - `if nose_y < eye_y`: 丢弃（鼻子不可能长在眼睛上面）。
   - `if mouth_y < nose_y`: 丢弃（嘴巴不可能长在鼻子上面）。
3. **效果** ：大幅降低误检率（False Positive Rate），提升系统鲁棒性。

### 3.3 创新模块三：伦理应用——隐私马赛克盾 (Privacy Mosaic Shield)

**核心技术** ：ROI 降采样与邻域插值（Downscaling & Nearest Neighbor Interpolation）。

- **功能描述** ：体现对“AI 伦理”的思考。当开启此模式时，系统不再“标记”人脸，而是实时“隐匿”人脸，模拟新闻报道中的隐私保护处理。
- **技术实现路径** ：

1. **锁定敏感区** ：获取人脸或眼睛的 ROI 区域 `roi = frame[y:y+h, x:x+w]`。
2. **降采样（破坏信息）** ：使用 `cv2.resize` 将 ROI 缩小为原来的 **$1/15$** 或 **$1/20$**。此时高频信息（面部细节）丢失。
3. **升采样（还原尺寸）** ：再次使用 `cv2.resize` 将图像放大回原始尺寸 `(w, h)`。
4. **关键算法** ：在放大时，必须指定插值方法为 **`cv2.INTER_NEAREST`（最近邻插值）** 。这会产生明显的锯齿状方块效果，即标准的“马赛克”。
5. **回填** ：将处理后的马赛克块覆盖回原图位置。

---

## 4. 项目实施路线图

### 步骤 1：构建基线 (The Baseline)

编写 `detect_face()`, `detect_eyes()`, `detect_pupil()` 等基础函数，完成所有 PDF 教材要求的复现，并截图保存作为“实验对照组”。

### 步骤 2：实现三大创新 (The Innovations)

编写一个主控制类 `FaceAugmenter`，包含三个方法：

1. `apply_mask(roi, mask_img)`: 对应创新模块 3.1。
2. `check_geometry(face_rect, feature_rect, type)`: 对应创新模块 3.2。
3. `apply_mosaic(roi, level)`: 对应创新模块 3.3。

### 步骤 3：交互集成

在 `while True` 循环中添加键盘监听（`cv2.waitKey`）：

- 按 `m` 键：切换 **Mask（面具）模式** 。
- 按 `p` 键：切换 **Privacy（隐私）模式** 。
- 按 `g` 键：开关 **Geometry（几何约束）** ，实时演示误检的消除。

---

## 5. 预期成果 (Deliverables)

1. **Python 源代码** ：结构清晰，包含 `HaarCascade` 基类和三个创新功能模块。
2. **演示视频/GIF** ：

- **场景一** ：展示素颜下的精准检测（几何约束生效，无误检）。
- **场景二** ：按下按键，脸上瞬间戴上独特的“黑神话”面具。
- **场景三** ：按下按键，面部瞬间被打上马赛克，展示隐私保护效果。

1. **实验报告** ：分析马赛克生成的原理（插值算法的区别）以及位运算在 AR 中的核心作用。

这份报告完整覆盖了基础要求，并清晰地界定了三个互不干扰但相辅相成的创新方向，非常适合作为期末作业的最终提交方案。
